# Summon

Un proxy inverso ligero en Rust que enruta las solicitudes de API de Claude Code a diferentes proveedores de LLM seg√∫n el nombre del modelo.

Mantiene tu autenticaci√≥n de suscripci√≥n existente de Anthropic (OAuth) mientras deriva modelos espec√≠ficos a proveedores externos (Z.AI, Kimi, etc.).

## Arquitectura

```
Claude Code CLI
  ‚îÇ ANTHROPIC_BASE_URL=http://127.0.0.1:18081
  ‚ñº
Proxy (servidor axum)
  ‚îú‚îÄ /v1/messages POST ‚Üí an√°lisis del campo model ‚Üí decisi√≥n de enrutamiento
  ‚îÇ   ‚îú‚îÄ Coincidencia ‚Üí Proveedor externo (reemplazo de encabezados/autenticaci√≥n)
  ‚îÇ   ‚îî‚îÄ Sin coincidencia ‚Üí Anthropic API (passthrough)
  ‚îî‚îÄ Otras solicitudes ‚Üí Anthropic API (passthrough)
```

## Instalaci√≥n

### Instalaci√≥n en una l√≠nea (Recomendado)

**Linux/macOS/WSL:**
```bash
curl -fsSL https://raw.githubusercontent.com/TheMagicTower/summon/master/install.sh | bash
```

**Windows (PowerShell):**
```powershell
irm https://raw.githubusercontent.com/TheMagicTower/summon/master/install.ps1 | iex
```

> üí° **Usuarios de WSL**: Puedes usar Claude Code tanto desde WSL como desde Windows. Consulta la secci√≥n [Uso de WSL](#uso-de-wsl) a continuaci√≥n para obtener m√°s detalles.

### Descarga de binarios

Descarga el binario para tu plataforma desde la p√°gina de [Releases](https://github.com/TheMagicTower/summon/releases).

| Plataforma | Archivo |
|------------|---------|
| Linux x86_64 | `summon-linux-amd64.tar.gz` |
| Linux ARM64 | `summon-linux-arm64.tar.gz` |
| macOS Intel | `summon-darwin-amd64.tar.gz` |
| macOS Apple Silicon | `summon-darwin-arm64.tar.gz` |
| Windows x86_64 | `summon-windows-amd64.zip` |
| Windows ARM64 | `summon-windows-arm64.zip` |

```bash
# Ejemplo: macOS Apple Silicon
tar xzf summon-darwin-arm64.tar.gz
chmod +x summon-darwin-arm64
sudo mv summon-darwin-arm64 /usr/local/bin/summon
```

### Construir desde el c√≥digo fuente

```bash
cargo build --release
```

## Configuraci√≥n

### Ubicaci√≥n del archivo de configuraci√≥n

summon busca archivos de configuraci√≥n en el siguiente orden de prioridad:

| Prioridad | Ubicaci√≥n | Descripci√≥n |
|-----------|-----------|-------------|
| 1 | `--config <ruta>` | Especificaci√≥n expl√≠cita |
| 2 | Variable de entorno `SUMMON_CONFIG` | Ruta especificada por variable de entorno |
| 3 | `~/.config/summon/config.yaml` | Configuraci√≥n espec√≠fica de usuario (XDG) |
| 4 | `/etc/summon/config.yaml` | Configuraci√≥n de todo el sistema |
| 5 | `./config.yaml` | Directorio actual |

### Entorno multiusuario

Para que cada usuario tenga su propia configuraci√≥n:
```bash
mkdir -p ~/.config/summon
cp /path/to/config.yaml ~/.config/summon/
```

Para que los administradores del sistema proporcionen una configuraci√≥n predeterminada:
```bash
sudo mkdir -p /etc/summon
sudo cp config.yaml /etc/summon/
```

### Enfoques de configuraci√≥n

Hay dos enfoques seg√∫n tu proveedor y caso de uso.

#### Enfoque 1: Proveedores compatibles (Paso de nombre de modelo)

Para proveedores que entienden nativamente los nombres de modelo de Anthropic (por ejemplo, Z.AI, Kimi). El nombre de modelo original de Claude Code se reenv√≠a tal cual.

```yaml
server:
  host: "127.0.0.1"
  port: 18081

default:
  url: "https://api.anthropic.com"

routes:
  - match: "claude-haiku"
    upstream:
      url: "https://api.z.ai/api/anthropic"
      auth:
        header: "x-api-key"
        value: "${Z_AI_API_KEY}"

  - match: "claude-sonnet"
    upstream:
      url: "https://api.kimi.com/coding"
      auth:
        header: "Authorization"
        value: "Bearer ${KIMI_API_KEY}"
```

- Claude Code env√≠a `model: "claude-haiku-4-5-20251001"` ‚Üí coincide con `"claude-haiku"` ‚Üí enrutado a Z.AI
- El proveedor decide qu√© modelo real usar para el nombre de modelo de Anthropic
- Configuraci√≥n simple, no se necesita configuraci√≥n adicional de Claude Code

#### Enfoque 2: Vinculaci√≥n de modelo personalizado (Selecci√≥n de modelo espec√≠fico)

Cuando quieres usar un modelo upstream espec√≠fico (por ejemplo, `glm-4.7` en lugar de lo que el proveedor mapea `claude-haiku`). Sobrescribe los nombres de modelo en `settings.json` de Claude Code:

**Paso 1.** Configura Claude Code para enviar nombres de modelo personalizados:

```json
// ~/.claude/settings.json
{
  "env": {
    "ANTHROPIC_BASE_URL": "http://127.0.0.1:18081",
    "ANTHROPIC_DEFAULT_HAIKU_MODEL": "glm-4.7",
    "ANTHROPIC_DEFAULT_SONNET_MODEL": "kimi-for-coding"
  }
}
```

| Variable de entorno | Descripci√≥n |
|---------------------|-------------|
| `ANTHROPIC_BASE_URL` | Direcci√≥n del proxy (tambi√©n elimina la necesidad de especificarla en cada inicio) |
| `ANTHROPIC_DEFAULT_HAIKU_MODEL` | Nombre de modelo enviado cuando se selecciona el nivel Haiku |
| `ANTHROPIC_DEFAULT_SONNET_MODEL` | Nombre de modelo enviado cuando se selecciona el nivel Sonnet |
| `ANTHROPIC_DEFAULT_OPUS_MODEL` | Nombre de modelo enviado cuando se selecciona el nivel Opus |

**Paso 2.** Coincide con los nombres de modelo sobrescritos en `config.yaml`:

```yaml
server:
  host: "127.0.0.1"
  port: 18081

default:
  url: "https://api.anthropic.com"

routes:
  - match: "glm"
    upstream:
      url: "https://api.z.ai/api/anthropic"
      auth:
        header: "x-api-key"
        value: "${Z_AI_API_KEY}"

  - match: "kimi"
    upstream:
      url: "https://api.kimi.com/coding"
      auth:
        header: "Authorization"
        value: "Bearer ${KIMI_API_KEY}"
```

- Claude Code env√≠a `model: "glm-4.7"` (sobrescrito) ‚Üí coincide con `"glm"` ‚Üí enrutado a Z.AI con el modelo exacto
- Controlas exactamente qu√© modelo usa el proveedor
- `ANTHROPIC_BASE_URL` en `settings.json` significa que puedes ejecutar `claude` sin variables de entorno adicionales

### Referencia de configuraci√≥n

- `match`: Coincide si esta cadena est√° contenida en el nombre del modelo (orden de arriba a abajo, se aplica la primera coincidencia)
- `${ENV_VAR}`: Referencia a variable de entorno (las claves de API no se escriben directamente en el archivo de configuraci√≥n)
- `upstream.auth.pool`: Valores adicionales de claves API para distribuci√≥n de carga (usa el mismo header que `auth.header`)
- `concurrency`: L√≠mite de solicitudes concurrentes por clave (cuando se excede, retrocede a Anthropic o devuelve 429)
- `fallback`: Si retroceder a Anthropic API en caso de fallo del proveedor (predeterminado: `true`)
- Los modelos que no coinciden se pasan a `default.url` (Anthropic API)

### Grupo de claves API (Manejo de l√≠mites de concurrencia)

Algunos proveedores limitan las solicitudes concurrentes por clave API (por ejemplo, GLM-5 permite solo 1 solicitud concurrente por clave). Puede registrar m√∫ltiples claves API como un grupo para aumentar la concurrencia total:

```yaml
routes:
  - match: "glm-5"
    concurrency: 1           # l√≠mite de solicitudes concurrentes por clave
    upstream:
      url: "https://open.bigmodel.cn/api/paas/v4"
      auth:
        header: "Authorization"
        value: "Bearer ${GLM_KEY_1}"
        pool:                 # claves adicionales (mismo header)
          - "Bearer ${GLM_KEY_2}"
          - "Bearer ${GLM_KEY_3}"
    transformer: "openai"
    model_map: "glm-5"
```

**C√≥mo funciona:**

- Las solicitudes se distribuyen a la clave con menos conexiones activas (**Least-Connections**)
- El uso concurrente de cada clave se rastrea y limita mediante la configuraci√≥n `concurrency`
- Cuando todas las claves alcanzan su l√≠mite: retrocede a Anthropic (si `fallback: true`) o devuelve HTTP 429
- Las respuestas de streaming liberan autom√°ticamente la clave cuando termina el flujo

## Ejecuci√≥n

```bash
# Establecer variables de entorno
export Z_AI_API_KEY="your-z-ai-key"
export KIMI_API_KEY="your-kimi-key"

# Iniciar proxy (archivo de configuraci√≥n detectado autom√°ticamente)
summon

# O especificar archivo de configuraci√≥n directamente
summon --config /path/to/config.yaml
```

### Conectando Claude Code

**Opci√≥n A: Manual (por sesi√≥n)**
```bash
ANTHROPIC_BASE_URL=http://127.0.0.1:18081 claude
```

**Opci√≥n B: Autom√°tico (recomendado)**

A√±ade a `~/.claude/settings.json` para no necesitar especificar la URL nunca m√°s:
```json
{
  "env": {
    "ANTHROPIC_BASE_URL": "http://127.0.0.1:18081"
  }
}
```

Luego simplemente ejecuta:
```bash
claude
```

## Gesti√≥n de CLI

### Auto-actualizaci√≥n

Verifica nuevas versiones y actualiza el binario en su lugar:

```bash
summon update
```

El comando de actualizaci√≥n:
1. Compara la versi√≥n actual con el √∫ltimo lanzamiento de GitHub
2. Solicita confirmaci√≥n si hay una versi√≥n m√°s nueva disponible
3. Descarga y reemplaza el binario autom√°ticamente

> Windows: La auto-actualizaci√≥n no es compatible. Usa `install.ps1` en su lugar.

### Comandos directos

Todos los comandos de gesti√≥n son de nivel superior:

```bash
summon status          # Mostrar estado actual
summon enable          # Habilitar proxy (modificar settings.json + iniciar)
summon disable         # Deshabilitar proxy (detener + restaurar settings.json)
summon start           # Iniciar proxy en segundo plano
summon stop            # Detener proxy
summon add             # Agregar una ruta de proveedor
summon remove          # Eliminar una ruta de proveedor
summon restore         # Restaurar settings.json desde respaldo
```

### Configuraci√≥n interactiva

Ejecutar `summon configure` abre un men√∫ interactivo con todas las acciones disponibles:

```bash
summon configure
```

## Uso de WSL

Tambi√©n puedes usar summon desde WSL (Windows Subsystem for Linux).

### Usar Claude Code desde el lado de WSL

```bash
# En terminal de WSL (asumiendo que el archivo de configuraci√≥n est√° en ~/.config/summon/config.yaml)
summon

# En otra terminal de WSL
ANTHROPIC_BASE_URL=http://127.0.0.1:18081 claude
```

### Usar Claude Code desde el lado de Windows (summon ejecut√°ndose en WSL)

```bash
# Ejecutar summon en WSL (enlazar a 0.0.0.0 para que sea accesible desde Windows)
summon

# En terminal de Windows (PowerShell/CMD)
# Verificar IP de WSL: ip addr show eth0 | grep 'inet '
ANTHROPIC_BASE_URL=http://$(wsl hostname -I | awk '{print $1}'):18081 claude
```

Alternativamente, puedes establecer `server.host` en `"0.0.0.0"` en `config.yaml` para que sea accesible desde Windows.

## Registrar como servicio en segundo plano

### macOS (launchd)

**1. Crear archivo plist de LaunchAgent:**

```bash
cat > ~/Library/LaunchAgents/com.themagictower.summon.plist << 'EOF'
<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE plist PUBLIC "-//Apple//DTD PLIST 1.0//EN" "http://www.apple.com/DTDs/PropertyList-1.0.dtd">
<plist version="1.0">
<dict>
    <key>Label</key>
    <string>com.themagictower.summon</string>
    <key>ProgramArguments</key>
    <array>
        <string>/Users/YOUR_USERNAME/.local/bin/summon</string>
        <string>--config</string>
        <string>/Users/YOUR_USERNAME/.config/summon/config.yaml</string>
    </array>
    <key>RunAtLoad</key>
    <true/>
    <key>KeepAlive</key>
    <true/>
    <key>StandardOutPath</key>
    <string>/Users/YOUR_USERNAME/.local/share/summon/summon.log</string>
    <key>StandardErrorPath</key>
    <string>/Users/YOUR_USERNAME/.local/share/summon/summon.error.log</string>
    <key>EnvironmentVariables</key>
    <dict>
        <key>PATH</key>
        <string>/Users/YOUR_USERNAME/.local/bin:/usr/local/bin:/usr/bin:/bin</string>
    </dict>
</dict>
</plist>
EOF
```

**2. Crear directorio de registros y registrar servicio:**

```bash
mkdir -p ~/.local/share/summon
launchctl load ~/Library/LaunchAgents/com.themagictower.summon.plist
launchctl start com.themagictower.summon
```

**3. Gesti√≥n del servicio:**

```bash
# Verificar estado
launchctl list | grep com.themagictower.summon

# Detener
launchctl stop com.themagictower.summon

# Reiniciar
launchctl stop com.themagictower.summon && launchctl start com.themagictower.summon

# Eliminar
launchctl unload ~/Library/LaunchAgents/com.themagictower.summon.plist
rm ~/Library/LaunchAgents/com.themagictower.summon.plist
```

### Windows (Windows Service)

**PowerShell (requiere privilegios de administrador):**

```powershell
# 1. Registrar summon como Windows Service (se recomienda nssm)
# Instalar nssm: winget install nssm

# Registrar servicio
nssm install Summon "$env:LOCALAPPDATA\summon\bin\summon.exe"
nssm set Summon AppParameters "--config `"$env:APPDATA\summon\config.yaml`""
nssm set Summon DisplayName "Summon LLM Proxy"
nssm set Summon Start SERVICE_AUTO_START

# Iniciar servicio
Start-Service Summon

# Gesti√≥n del servicio
Get-Service Summon      # Verificar estado
Stop-Service Summon     # Detener
Restart-Service Summon  # Reiniciar
sc delete Summon        # Eliminar
```

**O usar WinSW:**

```powershell
# Descargar y configurar WinSW
# https://github.com/winsw/winsw/releases

# Crear summon-service.xmlÔºö
@"
<service>
  <id>summon</id>
  <name>Summon LLM Proxy</name>
  <description>Model-based routing proxy for Claude Code</description>
  <executable>%LOCALAPPDATA%\summon\bin\summon.exe</executable>
  <arguments>--config "%APPDATA%\summon\config.yaml"</arguments>
  <log mode="roll-by-size">
    <sizeThreshold>10240</sizeThreshold>
    <keepFiles>8</keepFiles>
  </log>
</service>
"@ | Out-File "$env:LOCALAPPDATA\summon\bin\summon-service.xml" -Encoding UTF8

# Registrar e iniciar servicio
winsw install $env:LOCALAPPDATA\summon\bin\summon-service.xml
winsw start $env:LOCALAPPDATA\summon\bin\summon-service.xml
```

### Linux (systemd) - Incluyendo WSL

El script de instalaci√≥n detecta autom√°ticamente el entorno y selecciona el tipo de servicio apropiado:
- **Servicio de usuario**: Entorno de escritorio
- **Servicio del sistema**: Servidor sin cabeza (sesiones SSH, etc.)

#### M√©todo 1: Servicio de usuario (Entorno de escritorio)

**1. Crear archivo de servicio systemd:**

```bash
cat > ~/.config/systemd/user/summon.service << 'EOF'
[Unit]
Description=Summon LLM Proxy
After=network.target

[Service]
Type=simple
ExecStart=%h/.local/bin/summon --config %h/.config/summon/config.yaml
Restart=always
RestartSec=5
Environment="PATH=%h/.local/bin:/usr/local/bin:/usr/bin:/bin"

[Install]
WantedBy=default.target
EOF
```

**2. Registrar e iniciar servicio:**

```bash
# Cargar servicio de usuario
systemctl --user daemon-reload
systemctl --user enable summon.service
systemctl --user start summon.service

# Gesti√≥n del servicio
systemctl --user status summon    # Verificar estado
systemctl --user stop summon      # Detener
systemctl --user restart summon   # Reiniciar
systemctl --user disable summon   # Deshabilitar inicio autom√°tico
```

#### M√©todo 2: Servicio del sistema (Servidor sin cabeza)

Para entornos sin sesiones de usuario D-Bus como sesiones SSH, use un servicio a nivel del sistema. **Requiere privilegios sudo.**

**1. Crear archivo de servicio systemd (requiere sudo):**

```bash
sudo tee /etc/systemd/system/summon.service > /dev/null << 'EOF'
[Unit]
Description=Summon LLM Proxy
After=network.target

[Service]
Type=simple
User=$(whoami)
Group=$(id -gn)
ExecStart=/home/$(whoami)/.local/bin/summon --config /home/$(whoami)/.config/summon/config.yaml
Restart=always
RestartSec=5
Environment="PATH=/home/$(whoami)/.local/bin:/usr/local/bin:/usr/bin:/bin"

[Install]
WantedBy=multi-user.target
EOF
```

**2. Registrar e iniciar servicio (requiere sudo):**

```bash
# Cargar servicio del sistema
sudo systemctl daemon-reload
sudo systemctl enable summon.service
sudo systemctl start summon.service

# Gesti√≥n del servicio
sudo systemctl status summon    # Verificar estado
sudo systemctl stop summon      # Detener
sudo systemctl restart summon   # Reiniciar
sudo systemctl disable summon   # Deshabilitar inicio autom√°tico

# Ver registros
journalctl -u summon -f
```

> **Nota**: Para usar systemd en WSL2, es posible que necesites establecer `[boot] systemd=true` en `/etc/wsl.conf`.

## Caracter√≠sticas principales

- **Proxy transparente**: Claude Code no percibe la existencia del proxy
- **Enrutamiento basado en modelos**: Decisi√≥n de enrutamiento basada en el campo `model` en `/v1/messages` POST
- **Transmisi√≥n SSE**: Passthrough en tiempo real por fragmentos
- **Autenticaci√≥n de suscripci√≥n concurrente**: Los tokens OAuth de Anthropic permanecen intactos, solo los proveedores externos usan claves de API
- **Grupo de claves API**: Soporte para m√∫ltiples claves API por ruta con distribuci√≥n Least-Connections para proveedores con l√≠mites de concurrencia por clave
- **Seguridad**: Se enlaza solo a `127.0.0.1`, claves de API referenciadas desde variables de entorno

## ‚ö†Ô∏è Limitaciones conocidas

### No se pueden usar modelos de thinking de Anthropic despu√©s de cambiar a modelos externos

**Una vez que una conversaci√≥n ha cambiado a un modelo de un proveedor externo (Kimi, Z.AI, etc.), no puedes continuar con modelos de thinking de Anthropic (Claude Opus, Sonnet, etc.) en la misma conversaci√≥n.**

Esta es una limitaci√≥n de la arquitectura del sistema que no se puede resolver:
- Los proveedores externos no son completamente compatibles con el formato de mensaje nativo de Anthropic
- Los modelos de thinking dependen de campos nativos espec√≠ficos y estructuras de contexto
- Las respuestas de modelos externos no cumplen con el formato de contexto requerido por los modelos de thinking

**Uso recomendado:**
- Al cambiar modelos dentro de la misma sesi√≥n de conversaci√≥n, cambia solo entre modelos externos ‚Üî modelos externos
- Si necesitas modelos de thinking de Anthropic, **inicia una nueva conversaci√≥n**

## Hoja de ruta

- **v0.1** (actual): Passthrough + enrutamiento basado en modelos + transmisi√≥n SSE
- **v0.2**: Transformador (transformaci√≥n de solicitud/respuesta ‚Äî para proveedores incompatibles)
- **v0.3**: Registro, verificaci√≥n de salud, recarga en caliente, tiempo de espera

## Licencia

MIT
